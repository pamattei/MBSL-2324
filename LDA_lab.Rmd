---
title: "Linear Discriminant Analysis Lab - MSc Data Science UCA"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r, load libraries}
#install.packages("pgmm") # we'll use this package to load the data
#install.packages("mvtnorm")
library(pgmm)
library(mvtnorm)
```

Let's first load the wine data that we saw in the previous lecture.

```{r, load data}
data(wine)
head(wine)
```

For simplicity, we'll only look at two features: alcohol content and acidity. The label will also be binarised: Barolo wine versus not Barolo.

```{r, plot data}
X = as.matrix(wine[,c(2,4)])
y = (wine$Type==1)
plot(X, col = y+1)
```


Implement the Linear Discriminant Analysis (LDA) algorithm that we saw in the last lecture. LDA assumes that each class follows a Gaussian distribution with identical covariance but different means:
$$p(x|0) = N(x|\mu_0, \Sigma),$$
$$p(x|1) = N(x|\mu_1, \Sigma).$$

For this, you must infer $\mu_0$, $\mu_1$, and $\Sigma$ using maximum likelihood, as seen in the lectures.
